{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sai/git/neural-art/venv1/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "(227, 227, 3) (356, 536, 3)\n",
      "Image 0\n",
      "Newfoundland, Newfoundland dog 0.6542891\n",
      "flat-coated retriever 0.26487303\n",
      "Tibetan mastiff 0.06337582\n",
      "Afghan hound, Afghan 0.005979187\n",
      "groenendael 0.002276599\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'output1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ed84bd1855c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0minput_im_ind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0minds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_im_ind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_im_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output1' is not defined"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "#Michael Guerzhoy and Davi Frossard, 2016\n",
    "#AlexNet implementation in TensorFlow, with weights\n",
    "#Details: \n",
    "#http://www.cs.toronto.edu/~guerzhoy/tf_alexnet/\n",
    "#\n",
    "#With code from https://github.com/ethereon/caffe-tensorflow\n",
    "#Model from  https://github.com/BVLC/caffe/tree/master/models/bvlc_alexnet\n",
    "#Weights from Caffe converted using https://github.com/ethereon/caffe-tensorflow\n",
    "#\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "from numpy import *\n",
    "import os\n",
    "#from pylab import *\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.cbook as cbook\n",
    "import time\n",
    "from skimage import io, transform\n",
    "import matplotlib.image as mpimg\n",
    "#from scipy.ndimage import filters\n",
    "#import urllib\n",
    "#from numpy import random\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from caffe_classes import class_names\n",
    "\n",
    "train_x = zeros((1, 227,227,3)).astype(float32)\n",
    "train_y = zeros((1, 1000))\n",
    "xdim = train_x.shape[1:]\n",
    "ydim = train_y.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "#Read Image, and change to BGR\n",
    "\n",
    "\n",
    "im1 = (io.imread(\"data/dog.png\")[:,:,:3]).astype(float32)\n",
    "im1 = im1 - mean(im1)\n",
    "im1[:, :, 0], im1[:, :, 2] = im1[:, :, 2], im1[:, :, 0]\n",
    "\n",
    "im2 = (io.imread(\"data/brad_pitt.jpg\")[:,:,:3]).astype(float32)\n",
    "im2[:, :, 0], im2[:, :, 2] = im2[:, :, 2], im2[:, :, 0]\n",
    "\n",
    "\n",
    "################################################################################\n",
    "\n",
    "# (self.feed('data')\n",
    "#         .conv(11, 11, 96, 4, 4, padding='VALID', name='conv1')\n",
    "#         .lrn(2, 2e-05, 0.75, name='norm1')\n",
    "#         .max_pool(3, 3, 2, 2, padding='VALID', name='pool1')\n",
    "#         .conv(5, 5, 256, 1, 1, group=2, name='conv2')\n",
    "#         .lrn(2, 2e-05, 0.75, name='norm2')\n",
    "#         .max_pool(3, 3, 2, 2, padding='VALID', name='pool2')\n",
    "#         .conv(3, 3, 384, 1, 1, name='conv3')\n",
    "#         .conv(3, 3, 384, 1, 1, group=2, name='conv4')\n",
    "#         .conv(3, 3, 256, 1, 1, group=2, name='conv5')\n",
    "#         .fc(4096, name='fc6')\n",
    "#         .fc(4096, name='fc7')\n",
    "#         .fc(1000, relu=False, name='fc8')\n",
    "#         .softmax(name='prob'))\n",
    "\n",
    "#In Python 3.5, change this to:\n",
    "net_data = load(open(\"model/bvlc_alexnet.npy\", \"rb\"), encoding=\"latin1\").item()\n",
    "#net_data = load(\"bvlc_alexnet.npy\").item()\n",
    "\n",
    "def conv(input, kernel, biases, k_h, k_w, c_o, s_h, s_w,  padding=\"VALID\", group=1):\n",
    "    '''From https://github.com/ethereon/caffe-tensorflow\n",
    "    '''\n",
    "    c_i = input.get_shape()[-1]\n",
    "    assert c_i%group==0\n",
    "    assert c_o%group==0\n",
    "    convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\n",
    "    \n",
    "    \n",
    "    if group==1:\n",
    "        conv = convolve(input, kernel)\n",
    "    else:\n",
    "        input_groups =  tf.split(input, group, 3)   #tf.split(3, group, input)\n",
    "        kernel_groups = tf.split(kernel, group, 3)  #tf.split(3, group, kernel) \n",
    "        output_groups = [convolve(i, k) for i,k in zip(input_groups, kernel_groups)]\n",
    "        conv = tf.concat(output_groups, 3)          #tf.concat(3, output_groups)\n",
    "    return  tf.reshape(tf.nn.bias_add(conv, biases), [-1]+conv.get_shape().as_list()[1:])\n",
    "\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None,) + xdim)\n",
    "\n",
    "\n",
    "#conv1\n",
    "#conv(11, 11, 96, 4, 4, padding='VALID', name='conv1')\n",
    "k_h = 11; k_w = 11; c_o = 96; s_h = 4; s_w = 4\n",
    "conv1W = tf.Variable(net_data[\"conv1\"][0])\n",
    "conv1b = tf.Variable(net_data[\"conv1\"][1])\n",
    "conv1_in = conv(x, conv1W, conv1b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=1)\n",
    "conv1 = tf.nn.relu(conv1_in)\n",
    "\n",
    "#lrn1\n",
    "#lrn(2, 2e-05, 0.75, name='norm1')\n",
    "radius = 2; alpha = 2e-05; beta = 0.75; bias = 1.0\n",
    "lrn1 = tf.nn.local_response_normalization(conv1,\n",
    "                                                  depth_radius=radius,\n",
    "                                                  alpha=alpha,\n",
    "                                                  beta=beta,\n",
    "                                                  bias=bias)\n",
    "\n",
    "#maxpool1\n",
    "#max_pool(3, 3, 2, 2, padding='VALID', name='pool1')\n",
    "k_h = 3; k_w = 3; s_h = 2; s_w = 2; padding = 'VALID'\n",
    "maxpool1 = tf.nn.max_pool(lrn1, ksize=[1, k_h, k_w, 1], strides=[1, s_h, s_w, 1], padding=padding)\n",
    "\n",
    "\n",
    "#conv2\n",
    "#conv(5, 5, 256, 1, 1, group=2, name='conv2')\n",
    "k_h = 5; k_w = 5; c_o = 256; s_h = 1; s_w = 1; group = 2\n",
    "conv2W = tf.Variable(net_data[\"conv2\"][0])\n",
    "conv2b = tf.Variable(net_data[\"conv2\"][1])\n",
    "conv2_in = conv(maxpool1, conv2W, conv2b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
    "conv2 = tf.nn.relu(conv2_in)\n",
    "\n",
    "\n",
    "#lrn2\n",
    "#lrn(2, 2e-05, 0.75, name='norm2')\n",
    "radius = 2; alpha = 2e-05; beta = 0.75; bias = 1.0\n",
    "lrn2 = tf.nn.local_response_normalization(conv2,\n",
    "                                                  depth_radius=radius,\n",
    "                                                  alpha=alpha,\n",
    "                                                  beta=beta,\n",
    "                                                  bias=bias)\n",
    "\n",
    "#maxpool2\n",
    "#max_pool(3, 3, 2, 2, padding='VALID', name='pool2')                                                  \n",
    "k_h = 3; k_w = 3; s_h = 2; s_w = 2; padding = 'VALID'\n",
    "maxpool2 = tf.nn.max_pool(lrn2, ksize=[1, k_h, k_w, 1], strides=[1, s_h, s_w, 1], padding=padding)\n",
    "\n",
    "#conv3\n",
    "#conv(3, 3, 384, 1, 1, name='conv3')\n",
    "k_h = 3; k_w = 3; c_o = 384; s_h = 1; s_w = 1; group = 1\n",
    "conv3W = tf.Variable(net_data[\"conv3\"][0])\n",
    "conv3b = tf.Variable(net_data[\"conv3\"][1])\n",
    "conv3_in = conv(maxpool2, conv3W, conv3b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
    "conv3 = tf.nn.relu(conv3_in)\n",
    "\n",
    "#conv4\n",
    "#conv(3, 3, 384, 1, 1, group=2, name='conv4')\n",
    "k_h = 3; k_w = 3; c_o = 384; s_h = 1; s_w = 1; group = 2\n",
    "conv4W = tf.Variable(net_data[\"conv4\"][0])\n",
    "conv4b = tf.Variable(net_data[\"conv4\"][1])\n",
    "conv4_in = conv(conv3, conv4W, conv4b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
    "conv4 = tf.nn.relu(conv4_in)\n",
    "\n",
    "\n",
    "#conv5\n",
    "#conv(3, 3, 256, 1, 1, group=2, name='conv5')\n",
    "k_h = 3; k_w = 3; c_o = 256; s_h = 1; s_w = 1; group = 2\n",
    "conv5W = tf.Variable(net_data[\"conv5\"][0])\n",
    "conv5b = tf.Variable(net_data[\"conv5\"][1])\n",
    "conv5_in = conv(conv4, conv5W, conv5b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
    "conv5 = tf.nn.relu(conv5_in)\n",
    "\n",
    "#maxpool5\n",
    "#max_pool(3, 3, 2, 2, padding='VALID', name='pool5')\n",
    "k_h = 3; k_w = 3; s_h = 2; s_w = 2; padding = 'VALID'\n",
    "maxpool5 = tf.nn.max_pool(conv5, ksize=[1, k_h, k_w, 1], strides=[1, s_h, s_w, 1], padding=padding)\n",
    "\n",
    "#fc6\n",
    "#fc(4096, name='fc6')\n",
    "fc6W = tf.Variable(net_data[\"fc6\"][0])\n",
    "fc6b = tf.Variable(net_data[\"fc6\"][1])\n",
    "fc6 = tf.nn.relu_layer(tf.reshape(maxpool5, [-1, int(prod(maxpool5.get_shape()[1:]))]), fc6W, fc6b)\n",
    "\n",
    "#fc7\n",
    "#fc(4096, name='fc7')\n",
    "fc7W = tf.Variable(net_data[\"fc7\"][0])\n",
    "fc7b = tf.Variable(net_data[\"fc7\"][1])\n",
    "fc7 = tf.nn.relu_layer(fc6, fc7W, fc7b)\n",
    "\n",
    "#fc8\n",
    "#fc(1000, relu=False, name='fc8')\n",
    "fc8W = tf.Variable(net_data[\"fc8\"][0])\n",
    "fc8b = tf.Variable(net_data[\"fc8\"][1])\n",
    "fc8 = tf.nn.xw_plus_b(fc7, fc8W, fc8b)\n",
    "\n",
    "\n",
    "#prob\n",
    "#softmax(name='prob'))\n",
    "prob = tf.nn.softmax(fc8)\n",
    "#alexnet = build_alexnet(x)\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "t = time.time()\n",
    "print(im1.shape,im2.shape)\n",
    "\n",
    "#output1 = sess.run(alexnet, feed_dict = {x:[im1]})b\n",
    "output = sess.run(prob, feed_dict = {x:[im1]})\n",
    "################################################################################\n",
    "\n",
    "#Output:\n",
    "\n",
    "\n",
    "for input_im_ind in range(output.shape[0]):\n",
    "    inds = argsort(output)[input_im_ind,:]\n",
    "    print(\"Image\", input_im_ind)\n",
    "    for i in range(5):\n",
    "        print(class_names[inds[-1-i]], output[input_im_ind, inds[-1-i]])\n",
    "\n",
    "\n",
    "# for input_im_ind in range(output1.shape[0]):\n",
    "#     inds = argsort(output1)[input_im_ind,:]\n",
    "#     print(\"Image\", input_im_ind)\n",
    "#     for i in range(5):\n",
    "#         print(class_names[inds[-1-i]], output1[input_im_ind, inds[-1-i]])\n",
    "\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[135.93832 , 134.93832 , 135.93832 ],\n",
       "        [136.93832 , 135.93832 , 136.93832 ],\n",
       "        [133.93832 , 136.93832 , 133.93832 ],\n",
       "        ...,\n",
       "        [139.93832 , 138.93832 , 139.93832 ],\n",
       "        [138.93832 , 141.93832 , 138.93832 ],\n",
       "        [101.938324, 110.938324, 101.938324]],\n",
       "\n",
       "       [[134.93832 , 137.93832 , 134.93832 ],\n",
       "        [136.93832 , 137.93832 , 136.93832 ],\n",
       "        [133.93832 , 138.93832 , 133.93832 ],\n",
       "        ...,\n",
       "        [141.93832 , 140.93832 , 141.93832 ],\n",
       "        [138.93832 , 142.93832 , 138.93832 ],\n",
       "        [102.938324, 112.938324, 102.938324]],\n",
       "\n",
       "       [[134.93832 , 137.93832 , 134.93832 ],\n",
       "        [134.93832 , 135.93832 , 134.93832 ],\n",
       "        [134.93832 , 136.93832 , 134.93832 ],\n",
       "        ...,\n",
       "        [138.93832 , 137.93832 , 138.93832 ],\n",
       "        [138.93832 , 142.93832 , 138.93832 ],\n",
       "        [ 99.938324, 109.938324,  99.938324]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[137.93832 , 134.93832 , 137.93832 ],\n",
       "        [138.93832 , 136.93832 , 138.93832 ],\n",
       "        [130.93832 , 127.938324, 130.93832 ],\n",
       "        ...,\n",
       "        [ 99.938324,  89.938324,  99.938324],\n",
       "        [ 89.938324,  83.938324,  89.938324],\n",
       "        [ 81.938324,  74.938324,  81.938324]],\n",
       "\n",
       "       [[135.93832 , 135.93832 , 135.93832 ],\n",
       "        [140.93832 , 139.93832 , 140.93832 ],\n",
       "        [141.93832 , 135.93832 , 141.93832 ],\n",
       "        ...,\n",
       "        [ 96.938324,  88.938324,  96.938324],\n",
       "        [ 45.938324,  36.938324,  45.938324],\n",
       "        [-25.061676, -14.061676, -25.061676]],\n",
       "\n",
       "       [[140.93832 , 137.93832 , 140.93832 ],\n",
       "        [139.93832 , 135.93832 , 139.93832 ],\n",
       "        [138.93832 , 135.93832 , 138.93832 ],\n",
       "        ...,\n",
       "        [-28.061676, -24.061676, -28.061676],\n",
       "        [ 39.938324,  41.938324,  39.938324],\n",
       "        [ 81.938324,  75.938324,  81.938324]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01661031,  0.01653   , -0.00440676, ...,  0.01128037,\n",
       "         0.0026244 ,  0.00190801],\n",
       "       [ 0.00904957,  0.00442292,  0.00716145, ..., -0.00323977,\n",
       "        -0.01159758, -0.00412793],\n",
       "       [-0.00931892,  0.00400924, -0.00765333, ..., -0.00141205,\n",
       "         0.00752433,  0.00067253],\n",
       "       ...,\n",
       "       [ 0.00728364, -0.02101534,  0.00512468, ...,  0.00366057,\n",
       "         0.01404969, -0.00596138],\n",
       "       [-0.00744063, -0.00874046, -0.01317619, ..., -0.01179923,\n",
       "        -0.00719004,  0.00177226],\n",
       "       [ 0.00437124, -0.00886834, -0.00509693, ...,  0.02225287,\n",
       "         0.02012635, -0.00323885]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "var = [v for v in tf.trainable_variables() if v.name == 'fc8/Variable:0']\n",
    "var = var[0]\n",
    "par = sess.run(var)\n",
    "par\n",
    "\n",
    "sess.close()\n",
    "par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder\n",
      "Variable/initial_value\n",
      "Variable\n",
      "Variable/Assign\n",
      "Variable/read\n",
      "Variable_1/initial_value\n",
      "Variable_1\n",
      "Variable_1/Assign\n",
      "Variable_1/read\n",
      "Conv2D\n",
      "BiasAdd\n",
      "Reshape/shape\n",
      "Reshape\n",
      "Relu\n",
      "LRN\n",
      "MaxPool\n",
      "Variable_2/initial_value\n",
      "Variable_2\n",
      "Variable_2/Assign\n",
      "Variable_2/read\n",
      "Variable_3/initial_value\n",
      "Variable_3\n",
      "Variable_3/Assign\n",
      "Variable_3/read\n",
      "Const\n",
      "split/split_dim\n",
      "split\n",
      "Const_1\n",
      "split_1/split_dim\n",
      "split_1\n",
      "Conv2D_1\n",
      "Conv2D_2\n",
      "concat/axis\n",
      "concat\n",
      "BiasAdd_1\n",
      "Reshape_1/shape\n",
      "Reshape_1\n",
      "Relu_1\n",
      "LRN_1\n",
      "MaxPool_1\n",
      "Variable_4/initial_value\n",
      "Variable_4\n",
      "Variable_4/Assign\n",
      "Variable_4/read\n",
      "Variable_5/initial_value\n",
      "Variable_5\n",
      "Variable_5/Assign\n",
      "Variable_5/read\n",
      "Conv2D_3\n",
      "BiasAdd_2\n",
      "Reshape_2/shape\n",
      "Reshape_2\n",
      "Relu_2\n",
      "Variable_6/initial_value\n",
      "Variable_6\n",
      "Variable_6/Assign\n",
      "Variable_6/read\n",
      "Variable_7/initial_value\n",
      "Variable_7\n",
      "Variable_7/Assign\n",
      "Variable_7/read\n",
      "Const_2\n",
      "split_2/split_dim\n",
      "split_2\n",
      "Const_3\n",
      "split_3/split_dim\n",
      "split_3\n",
      "Conv2D_4\n",
      "Conv2D_5\n",
      "concat_1/axis\n",
      "concat_1\n",
      "BiasAdd_3\n",
      "Reshape_3/shape\n",
      "Reshape_3\n",
      "Relu_3\n",
      "Variable_8/initial_value\n",
      "Variable_8\n",
      "Variable_8/Assign\n",
      "Variable_8/read\n",
      "Variable_9/initial_value\n",
      "Variable_9\n",
      "Variable_9/Assign\n",
      "Variable_9/read\n",
      "Const_4\n",
      "split_4/split_dim\n",
      "split_4\n",
      "Const_5\n",
      "split_5/split_dim\n",
      "split_5\n",
      "Conv2D_6\n",
      "Conv2D_7\n",
      "concat_2/axis\n",
      "concat_2\n",
      "BiasAdd_4\n",
      "Reshape_4/shape\n",
      "Reshape_4\n",
      "Relu_4\n",
      "MaxPool_2\n",
      "Variable_10/initial_value\n",
      "Variable_10\n",
      "Variable_10/Assign\n",
      "Variable_10/read\n",
      "Variable_11/initial_value\n",
      "Variable_11\n",
      "Variable_11/Assign\n",
      "Variable_11/read\n",
      "Reshape_5/shape\n",
      "Reshape_5\n",
      "relu_layer/MatMul\n",
      "relu_layer/BiasAdd\n",
      "relu_layer\n",
      "Variable_12/initial_value\n",
      "Variable_12\n",
      "Variable_12/Assign\n",
      "Variable_12/read\n",
      "Variable_13/initial_value\n",
      "Variable_13\n",
      "Variable_13/Assign\n",
      "Variable_13/read\n",
      "relu_layer_1/MatMul\n",
      "relu_layer_1/BiasAdd\n",
      "relu_layer_1\n",
      "Variable_14/initial_value\n",
      "Variable_14\n",
      "Variable_14/Assign\n",
      "Variable_14/read\n",
      "Variable_15/initial_value\n",
      "Variable_15\n",
      "Variable_15/Assign\n",
      "Variable_15/read\n",
      "xw_plus_b/MatMul\n",
      "xw_plus_b\n",
      "Softmax\n",
      "init\n",
      "init_1\n",
      "init_2\n",
      "init_3\n",
      "init_4\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for op in sess.graph.get_operations():\n",
    "    #if op.name == \"relu_layer_5/MatMul\":\n",
    "        #p = sess.run(conv4, feed_dict = {x:[im1]})\n",
    "        #p = sess.run(conv4, feed_dict = {x:[im1]})\n",
    "    print(op.name)\n",
    "#p = sess.run(conv4, feed_dict = {x:[im1]})\n",
    "#print(p)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[135.93832  134.93832  135.93832 ]\n",
      "   [136.93832  135.93832  136.93832 ]\n",
      "   [133.93832  136.93832  133.93832 ]\n",
      "   ...\n",
      "   [139.93832  138.93832  139.93832 ]\n",
      "   [138.93832  141.93832  138.93832 ]\n",
      "   [101.938324 110.938324 101.938324]]\n",
      "\n",
      "  [[134.93832  137.93832  134.93832 ]\n",
      "   [136.93832  137.93832  136.93832 ]\n",
      "   [133.93832  138.93832  133.93832 ]\n",
      "   ...\n",
      "   [141.93832  140.93832  141.93832 ]\n",
      "   [138.93832  142.93832  138.93832 ]\n",
      "   [102.938324 112.938324 102.938324]]\n",
      "\n",
      "  [[134.93832  137.93832  134.93832 ]\n",
      "   [134.93832  135.93832  134.93832 ]\n",
      "   [134.93832  136.93832  134.93832 ]\n",
      "   ...\n",
      "   [138.93832  137.93832  138.93832 ]\n",
      "   [138.93832  142.93832  138.93832 ]\n",
      "   [ 99.938324 109.938324  99.938324]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[137.93832  134.93832  137.93832 ]\n",
      "   [138.93832  136.93832  138.93832 ]\n",
      "   [130.93832  127.938324 130.93832 ]\n",
      "   ...\n",
      "   [ 99.938324  89.938324  99.938324]\n",
      "   [ 89.938324  83.938324  89.938324]\n",
      "   [ 81.938324  74.938324  81.938324]]\n",
      "\n",
      "  [[135.93832  135.93832  135.93832 ]\n",
      "   [140.93832  139.93832  140.93832 ]\n",
      "   [141.93832  135.93832  141.93832 ]\n",
      "   ...\n",
      "   [ 96.938324  88.938324  96.938324]\n",
      "   [ 45.938324  36.938324  45.938324]\n",
      "   [-25.061676 -14.061676 -25.061676]]\n",
      "\n",
      "  [[140.93832  137.93832  140.93832 ]\n",
      "   [139.93832  135.93832  139.93832 ]\n",
      "   [138.93832  135.93832  138.93832 ]\n",
      "   ...\n",
      "   [-28.061676 -24.061676 -28.061676]\n",
      "   [ 39.938324  41.938324  39.938324]\n",
      "   [ 81.938324  75.938324  81.938324]]]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "#for op in sess.graph.get_operations():\n",
    "    #if op.name == \"relu_layer_5/MatMul\":\n",
    "        #p = sess.run(conv4, feed_dict = {x:[im1]})\n",
    "        #p = sess.run(conv4, feed_dict = {x:[im1]})\n",
    "    #print(op.name)\n",
    "p = sess.run(x, feed_dict = {x:[im1]})\n",
    "print(p)\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
